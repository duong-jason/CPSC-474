{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbf97043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from statistics import mode\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8501821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_pickle(r'/home/jason/Desktop/school/dc/distrf/dataset/cancer.pkl')\n",
    "# X, y = df.iloc[:, :-1], df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f3966a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TESTING ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59fa4509",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"/Users/duong-jason/Desktop/dc/distrf/dataset/golf.csv\")\n",
    "X, y = df.iloc[:, :-1], df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94b37c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TESTING ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db25b7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff0a4a2",
   "metadata": {},
   "source": [
    "# Decision Tree Implementation\n",
    "### Entropy *(Bits)*\n",
    "$\\mathcal{H}(t, \\mathcal{D})=-\\sum_{I\\in levels(t)\\\\}^{}{P(t=I)\\cdot\\log_2(P(t=I))}$\n",
    "\n",
    "### Rem\n",
    "$rem(d,\\mathcal{D})=\\sum_{I\\in levels(t)}{}\\frac{|\\mathcal{D}_{d=I}|}{\\mathcal{D}}\\cdot \\mathcal{H}(t, \\mathcal{D}_{d=I})$\n",
    "\n",
    "### Information Gain\n",
    "$IG(d, \\mathcal{D})=\\mathcal{H}(t, \\mathcal{D})-rem(d, \\mathcal{D})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "288856b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        feature=None,\n",
    "        data=None,\n",
    "        branch=None,\n",
    "        parent=None,\n",
    "        leaf=False,\n",
    "        children=[]\n",
    "    ):\n",
    "        self.feature = feature\n",
    "        self.data = data\n",
    "        self.branch = branch\n",
    "        self.parent = parent\n",
    "        self.leaf = leaf\n",
    "        self.children = children\n",
    "\n",
    "    @property\n",
    "    def isLeaf(self):\n",
    "        return self.leaf\n",
    "\n",
    "    @property\n",
    "    def X(self):\n",
    "        return self.data.iloc[:, :-1]\n",
    "\n",
    "    @property\n",
    "    def y(self):\n",
    "        return self.data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65ed769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    \"\"\"A Rudimentary Decision Tree Classifier\"\"\"\n",
    "    def __init__(self, *, criterion=None):\n",
    "        \"\"\"\n",
    "        Pre-pruning criterion = {max_depth, partition_threshold, low_gain}\n",
    "        \"\"\"\n",
    "        self.root = None\n",
    "        self.levels = None\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def __repr__(self, node=None, depth=0):\n",
    "        \"\"\"Displays the decision tree\"\"\"\n",
    "        if not node:\n",
    "            node = self.root\n",
    "\n",
    "        print(depth * '\\t', node.feature, f\"(Branch={node.branch})\")\n",
    "        for child in node.children:\n",
    "            self.__repr__(child, depth+1)\n",
    "\n",
    "        return \"\"\n",
    "\n",
    "    def partition(self, X, y, d, t):\n",
    "        D = pd.concat([X.loc[X[d]==t], y.loc[X[d]==t]], axis=1)\n",
    "        D = D.drop([d], axis=1)\n",
    "        return D.iloc[:, :-1], D.iloc[:, -1], t\n",
    "\n",
    "    def entropy(self, X, y):\n",
    "        \"\"\"Measures the amount of uncertainty/impurity/heterogeneity in (X, y)\"\"\"\n",
    "        proba = lambda t: len(X.loc[y==t]) / len(X)\n",
    "        return -sum([proba(t) * np.log2(proba(t)) for t in y.unique()])\n",
    "\n",
    "    def rem(self, X, y, d):\n",
    "        \"\"\"Measures the entropy after partitioning (X, y) on feature (d)\"\"\"\n",
    "        weight = lambda t: len(X.loc[X[d]==t]) / len(X)\n",
    "        return sum([weight(t) * self.entropy(X.loc[X[d]==t], y.loc[X[d]==t]) for t in X[d].unique()])\n",
    "\n",
    "    def information_gain(self, X, y, d):\n",
    "        \"\"\"Measures the reduction in the overall entropy in (X, y) achieved by testing on feature (d)\"\"\"\n",
    "        if debug:\n",
    "            print(f\"{d} = {self.entropy(X, y):.3f} - {self.rem(X, y, d):.3f} = {self.entropy(X, y) - self.rem(X, y, d):.3f}\") \n",
    "\n",
    "        return self.entropy(X, y) - self.rem(X, y, d)\n",
    "\n",
    "    def build_tree(self, X, y, *, parent=None, branch=None, depth=0):\n",
    "        \"\"\"Performs the ID3 algorithm\"\"\"\n",
    "        if len(y.unique()) == 1:  # all instances have the same target feature values\n",
    "            if debug:\n",
    "                print(\"All instances have the same target feature value\\n\")\n",
    "            return Node(feature=y.iat[0],\n",
    "                        data=pd.concat([X, y], axis=1),\n",
    "                        branch=branch,\n",
    "                        parent=parent,\n",
    "                        leaf=True)\n",
    "        elif X.empty:  # dataset is empty, return a leaf node labeled with the majority class of the parent\n",
    "            if debug:\n",
    "                print(\"Dataset is empty\\n\")\n",
    "            return Node(feature=mode(parent.y),\n",
    "                        branch=branch,\n",
    "                        parent=parent,\n",
    "                        leaf=True)\n",
    "        elif all((X[d] == X[d].iloc[0]).all() for d in X.columns):  # if all feature values are identical\n",
    "            if debug:\n",
    "                print(\"All instances have the same descriptive features\\n\")\n",
    "                return Node(feature=mode(y),\n",
    "                            data=pd.concat([X, y], axis=1),\n",
    "                            branch=branch,\n",
    "                            parent=parent,\n",
    "                            leaf=True)\n",
    "        elif self.criterion.get(\"max_depth\"):\n",
    "            if depth >= self.criterion[\"max_depth\"]:\n",
    "                if debug:\n",
    "                    print(\"Stopping at Max Depth\\n\")\n",
    "                return Node(feature=mode(y),\n",
    "                            data=pd.concat([X, y], axis=1),\n",
    "                            branch=branch,\n",
    "                            parent=parent,\n",
    "                            leaf=True)\n",
    "        elif self.criterion.get(\"partition_threshold\"):\n",
    "            if len(X) < self.criterion[\"partition_threshold\"]:\n",
    "                if debug:\n",
    "                    print(f\"Stopping at {len(X)} instances\\n\")\n",
    "                return Node(feature=mode(y),\n",
    "                            data=pd.concat([X, y], axis=1),\n",
    "                            branch=branch,\n",
    "                            parent=parent,\n",
    "                            leaf=True)\n",
    "\n",
    "        if debug:\n",
    "            print(\"===Information Gain===\")\n",
    "\n",
    "        gain = np.argmax([self.information_gain(X, y, d) for d in X.columns])\n",
    "\n",
    "        if self.criterion.get('low_gain'):\n",
    "            if gain <= self.criterion[\"low_gain\"]:\n",
    "                if debug:\n",
    "                    print(f\"Stopping at Gain={gain}\\n\")\n",
    "                return Node(feature=mode(y),\n",
    "                            data=pd.concat([X, y], axis=1),\n",
    "                            branch=branch,\n",
    "                            parent=parent,\n",
    "                            leaf=True)\n",
    "\n",
    "        best_feature = X.columns[gain]\n",
    "        best_node = deepcopy(Node(feature=best_feature,\n",
    "                                  data=pd.concat([X, y], axis=1),\n",
    "                                  branch=branch,\n",
    "                                  parent=parent))\n",
    "\n",
    "        if debug:\n",
    "            print()\n",
    "            print(\"===Best Feature===\")\n",
    "            print(best_feature)\n",
    "            print()\n",
    "\n",
    "        partitions = [self.partition(X, y, best_feature, t) for t in self.levels[best_feature]]\n",
    "\n",
    "        for *d, t in partitions:\n",
    "            if debug:\n",
    "                print(f\"===Partitioned Dataset ({t})===\")\n",
    "                print(pd.concat(d, axis=1).head())\n",
    "                print()\n",
    "            best_node.children.append(self.build_tree(*d, parent=best_node, branch=t, depth=depth+1))\n",
    "        return best_node\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.levels = {k: X[k].unique() for k in X.columns}\n",
    "        self.root = self.build_tree(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        node = self.root\n",
    "        while not node.isLeaf:\n",
    "            for child in node.children:\n",
    "                if child.branch == x.get(node.feature).values:\n",
    "                    node = child\n",
    "                    break\n",
    "        return node.feature\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y_hat = [self.predict(X.iloc[x].to_frame().T) for x in range(len(X))]\n",
    "        # return confusion_matrix(y, y_hat, labels=[1, 0])\n",
    "        return confusion_matrix(y, y_hat, labels=y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "248a88d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d96c2383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Information Gain===\n",
      "Outlook = 0.994 - 0.736 = 0.258\n",
      "Temperature = 0.994 - 0.909 = 0.085\n",
      "Humidity = 0.994 - 0.683 = 0.311\n",
      "Windy = 0.994 - 0.844 = 0.150\n",
      "\n",
      "===Best Feature===\n",
      "Humidity\n",
      "\n",
      "===Partitioned Dataset (normal)===\n",
      "     Outlook Temperature  Windy Play\n",
      "4      rainy        cool  False  yes\n",
      "12  overcast         hot  False  yes\n",
      "6   overcast        cool   True  yes\n",
      "5      rainy        cool   True   no\n",
      "8      sunny        cool  False  yes\n",
      "\n",
      "===Information Gain===\n",
      "Outlook = 0.650 - 0.459 = 0.191\n",
      "Temperature = 0.650 - 0.541 = 0.109\n",
      "Windy = 0.650 - 0.333 = 0.317\n",
      "\n",
      "===Best Feature===\n",
      "Windy\n",
      "\n",
      "===Partitioned Dataset (False)===\n",
      "     Outlook Temperature Play\n",
      "4      rainy        cool  yes\n",
      "12  overcast         hot  yes\n",
      "8      sunny        cool  yes\n",
      "9      rainy        mild  yes\n",
      "\n",
      "All instances have the same target feature value\n",
      "\n",
      "===Partitioned Dataset (True)===\n",
      "    Outlook Temperature Play\n",
      "6  overcast        cool  yes\n",
      "5     rainy        cool   no\n",
      "\n",
      "===Information Gain===\n",
      "Outlook = 1.000 - 0.000 = 1.000\n",
      "Temperature = 1.000 - 1.000 = 0.000\n",
      "Stopping at Gain=0\n",
      "\n",
      "===Partitioned Dataset (high)===\n",
      "   Outlook Temperature  Windy Play\n",
      "13   rainy        mild   True   no\n",
      "3    rainy        mild  False  yes\n",
      "1    sunny         hot   True   no\n",
      "7    sunny        mild  False   no\n",
      "0    sunny         hot  False   no\n",
      "\n",
      "===Information Gain===\n",
      "Outlook = 0.722 - 0.400 = 0.322\n",
      "Temperature = 0.722 - 0.551 = 0.171\n",
      "Windy = 0.722 - 0.551 = 0.171\n",
      "Stopping at Gain=0\n",
      "\n",
      "CPU times: user 55.1 ms, sys: 1.05 ms, total: 56.2 ms\n",
      "Wall time: 55.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dt = DecisionTree(criterion={'low_gain': 5e-2}).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6eb2907a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Humidity (Branch=None)\n",
      "\t Windy (Branch=normal)\n",
      "\t\t yes (Branch=False)\n",
      "\t\t yes (Branch=True)\n",
      "\t no (Branch=high)\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3da656ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9885a388",
   "metadata": {},
   "source": [
    "# Random Forest Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "454ac107-8855-4862-8582-e1f55e2f6ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, n_estimators=5, n_sample=2, criterion=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.n_sample = n_sample\n",
    "        self.forest = [DecisionTree(criterion=criterion) for _ in range(n_estimators)]\n",
    "\n",
    "    def sub_sample(self, X, n_sample=2):\n",
    "        \"\"\"Enforces feature randomness\"\"\"\n",
    "        return np.random.choice(X.columns.to_numpy(), n_sample, replace=False)\n",
    "\n",
    "    def bootstrap_sample(self, X, y, n_sample, key=True):\n",
    "        feature_subset = self.sub_sample(X, int(np.log2(len(X))))\n",
    "        d = pd.concat([X, y], axis=1)\n",
    "        d = d.sample(n=n_sample, replace=key)\n",
    "        return d.iloc[:, :-1][feature_subset], d.iloc[:, -1]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for tree in self.forest:\n",
    "            tree.fit(*self.bootstrap_sample(X, y, self.n_sample))\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        assert all(isinstance(model, DecisionTree) for model in self.forest)\n",
    "        return mode([dt.predict(x) for dt in self.forest])\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y_hat = [self.predict(X.iloc[x].to_frame().T) for x in range(len(X))]\n",
    "        # return confusion_matrix(y, y_hat, labels=[1, 0])\n",
    "        return confusion_matrix(y, y_hat, labels=y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08d17d4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Information Gain===\n",
      "Humidity = 0.845 - 0.545 = 0.300\n",
      "Temperature = 0.845 - 0.736 = 0.109\n",
      "Windy = 0.845 - 0.740 = 0.105\n",
      "\n",
      "===Best Feature===\n",
      "Humidity\n",
      "\n",
      "===Partitioned Dataset (high)===\n",
      "   Temperature  Windy Play\n",
      "1          hot   True   no\n",
      "7         mild  False   no\n",
      "1          hot   True   no\n",
      "13        mild   True   no\n",
      "7         mild  False   no\n",
      "\n",
      "All instances have the same target feature value\n",
      "\n",
      "===Partitioned Dataset (normal)===\n",
      "  Temperature  Windy Play\n",
      "5        cool   True   no\n",
      "9        mild  False  yes\n",
      "8        cool  False  yes\n",
      "6        cool   True  yes\n",
      "5        cool   True   no\n",
      "\n",
      "===Information Gain===\n",
      "Temperature = 1.000 - 0.809 = 0.191\n",
      "Windy = 1.000 - 0.541 = 0.459\n",
      "\n",
      "===Best Feature===\n",
      "Windy\n",
      "\n",
      "===Partitioned Dataset (True)===\n",
      "  Temperature Play\n",
      "5        cool   no\n",
      "6        cool  yes\n",
      "5        cool   no\n",
      "5        cool   no\n",
      "\n",
      "All instances have the same descriptive features\n",
      "\n",
      "===Partitioned Dataset (False)===\n",
      "  Temperature Play\n",
      "9        mild  yes\n",
      "8        cool  yes\n",
      "\n",
      "All instances have the same target feature value\n",
      "\n",
      "===Information Gain===\n",
      "Windy = 0.946 - 0.840 = 0.105\n",
      "Humidity = 0.946 - 0.000 = 0.946\n",
      "Outlook = 0.946 - 0.692 = 0.254\n",
      "\n",
      "===Best Feature===\n",
      "Humidity\n",
      "\n",
      "===Partitioned Dataset (normal)===\n",
      "    Windy   Outlook Play\n",
      "6    True  overcast  yes\n",
      "12  False  overcast  yes\n",
      "9   False     rainy  yes\n",
      "4   False     rainy  yes\n",
      "12  False  overcast  yes\n",
      "\n",
      "All instances have the same target feature value\n",
      "\n",
      "===Partitioned Dataset (high)===\n",
      "    Windy Outlook Play\n",
      "0   False   sunny   no\n",
      "13   True   rainy   no\n",
      "13   True   rainy   no\n",
      "0   False   sunny   no\n",
      "\n",
      "All instances have the same target feature value\n",
      "\n",
      "===Information Gain===\n",
      "Outlook = 0.994 - 0.727 = 0.267\n",
      "Temperature = 0.994 - 0.978 = 0.016\n",
      "Windy = 0.994 - 0.355 = 0.639\n",
      "\n",
      "===Best Feature===\n",
      "Windy\n",
      "\n",
      "===Partitioned Dataset (True)===\n",
      "   Outlook Temperature Play\n",
      "5    rainy        cool   no\n",
      "1    sunny         hot   no\n",
      "13   rainy        mild   no\n",
      "5    rainy        cool   no\n",
      "13   rainy        mild   no\n",
      "\n",
      "All instances have the same target feature value\n",
      "\n",
      "===Partitioned Dataset (False)===\n",
      "     Outlook Temperature Play\n",
      "7      sunny        mild   no\n",
      "9      rainy        mild  yes\n",
      "4      rainy        cool  yes\n",
      "9      rainy        mild  yes\n",
      "12  overcast         hot  yes\n",
      "\n",
      "===Information Gain===\n",
      "Outlook = 0.650 - 0.000 = 0.650\n",
      "Temperature = 0.650 - 0.541 = 0.109\n",
      "\n",
      "===Best Feature===\n",
      "Outlook\n",
      "\n",
      "===Partitioned Dataset (rainy)===\n",
      "  Temperature Play\n",
      "9        mild  yes\n",
      "4        cool  yes\n",
      "9        mild  yes\n",
      "3        mild  yes\n",
      "\n",
      "All instances have the same target feature value\n",
      "\n",
      "===Partitioned Dataset (sunny)===\n",
      "  Temperature Play\n",
      "7        mild   no\n",
      "\n",
      "All instances have the same target feature value\n",
      "\n",
      "===Partitioned Dataset (overcast)===\n",
      "   Temperature Play\n",
      "12         hot  yes\n",
      "\n",
      "All instances have the same target feature value\n",
      "\n",
      "===Information Gain===\n",
      "Outlook = 0.994 - 0.000 = 0.994\n",
      "Windy = 0.994 - 0.993 = 0.001\n",
      "Humidity = 0.994 - 0.355 = 0.639\n",
      "\n",
      "===Best Feature===\n",
      "Outlook\n",
      "\n",
      "===Partitioned Dataset (sunny)===\n",
      "   Windy Humidity Play\n",
      "7  False     high   no\n",
      "7  False     high   no\n",
      "1   True     high   no\n",
      "0  False     high   no\n",
      "7  False     high   no\n",
      "\n",
      "All instances have the same target feature value\n",
      "\n",
      "===Partitioned Dataset (rainy)===\n",
      "   Windy Humidity Play\n",
      "3  False     high  yes\n",
      "4  False   normal  yes\n",
      "9  False   normal  yes\n",
      "\n",
      "All instances have the same target feature value\n",
      "\n",
      "===Partitioned Dataset (overcast)===\n",
      "    Windy Humidity Play\n",
      "12  False   normal  yes\n",
      "6    True   normal  yes\n",
      "12  False   normal  yes\n",
      "\n",
      "All instances have the same target feature value\n",
      "\n",
      "===Information Gain===\n",
      "Temperature = 0.994 - 0.751 = 0.243\n",
      "Humidity = 0.994 - 0.549 = 0.445\n",
      "Windy = 0.994 - 0.987 = 0.007\n",
      "\n",
      "===Best Feature===\n",
      "Humidity\n",
      "\n",
      "===Partitioned Dataset (high)===\n",
      "  Temperature  Windy Play\n",
      "0         hot  False   no\n",
      "1         hot   True   no\n",
      "7        mild  False   no\n",
      "7        mild  False   no\n",
      "\n",
      "All instances have the same target feature value\n",
      "\n",
      "===Partitioned Dataset (normal)===\n",
      "   Temperature  Windy Play\n",
      "5         cool   True   no\n",
      "12         hot  False  yes\n",
      "6         cool   True  yes\n",
      "5         cool   True   no\n",
      "4         cool  False  yes\n",
      "\n",
      "===Information Gain===\n",
      "Temperature = 0.863 - 0.787 = 0.076\n",
      "Windy = 0.863 - 0.571 = 0.292\n",
      "\n",
      "===Best Feature===\n",
      "Windy\n",
      "\n",
      "===Partitioned Dataset (False)===\n",
      "   Temperature Play\n",
      "12         hot  yes\n",
      "4         cool  yes\n",
      "4         cool  yes\n",
      "\n",
      "All instances have the same target feature value\n",
      "\n",
      "===Partitioned Dataset (True)===\n",
      "  Temperature Play\n",
      "5        cool   no\n",
      "6        cool  yes\n",
      "5        cool   no\n",
      "6        cool  yes\n",
      "\n",
      "All instances have the same descriptive features\n",
      "\n",
      "===Information Gain===\n",
      "Outlook = 0.946 - 0.809 = 0.137\n",
      "Humidity = 0.946 - 0.840 = 0.105\n",
      "Temperature = 0.946 - 0.918 = 0.027\n",
      "\n",
      "===Best Feature===\n",
      "Outlook\n",
      "\n",
      "===Partitioned Dataset (overcast)===\n",
      "   Humidity Temperature Play\n",
      "6    normal        cool  yes\n",
      "12   normal         hot  yes\n",
      "\n",
      "All instances have the same target feature value\n",
      "\n",
      "===Partitioned Dataset (rainy)===\n",
      "   Humidity Temperature Play\n",
      "4    normal        cool  yes\n",
      "13     high        mild   no\n",
      "3      high        mild  yes\n",
      "5    normal        cool   no\n",
      "9    normal        mild  yes\n",
      "\n",
      "===Information Gain===\n",
      "Humidity = 0.985 - 0.979 = 0.006\n",
      "Temperature = 0.985 - 0.857 = 0.128\n",
      "\n",
      "===Best Feature===\n",
      "Temperature\n",
      "\n",
      "===Partitioned Dataset (cool)===\n",
      "  Humidity Play\n",
      "4   normal  yes\n",
      "5   normal   no\n",
      "5   normal   no\n",
      "\n",
      "All instances have the same descriptive features\n",
      "\n",
      "===Partitioned Dataset (mild)===\n",
      "   Humidity Play\n",
      "13     high   no\n",
      "3      high  yes\n",
      "9    normal  yes\n",
      "9    normal  yes\n",
      "\n",
      "Stopping at 4 instances\n",
      "\n",
      "===Partitioned Dataset (hot)===\n",
      "Empty DataFrame\n",
      "Columns: [Humidity, Play]\n",
      "Index: []\n",
      "\n",
      "Dataset is empty\n",
      "\n",
      "===Partitioned Dataset (sunny)===\n",
      "  Humidity Temperature Play\n",
      "8   normal        cool  yes\n",
      "0     high         hot   no\n",
      "\n",
      "Stopping at 2 instances\n",
      "\n",
      "===Information Gain===\n",
      "Temperature = 0.845 - 0.545 = 0.300\n",
      "Outlook = 0.845 - 0.659 = 0.187\n",
      "Windy = 0.845 - 0.740 = 0.105\n",
      "\n",
      "===Best Feature===\n",
      "Temperature\n",
      "\n",
      "===Partitioned Dataset (cool)===\n",
      "    Outlook  Windy Play\n",
      "8     sunny  False  yes\n",
      "6  overcast   True  yes\n",
      "4     rainy  False  yes\n",
      "8     sunny  False  yes\n",
      "6  overcast   True  yes\n",
      "\n",
      "All instances have the same target feature value\n",
      "\n",
      "===Partitioned Dataset (mild)===\n",
      "   Outlook  Windy Play\n",
      "7    sunny  False   no\n",
      "9    rainy  False  yes\n",
      "13   rainy   True   no\n",
      "3    rainy  False  yes\n",
      "\n",
      "Stopping at 4 instances\n",
      "\n",
      "===Partitioned Dataset (hot)===\n",
      "     Outlook  Windy Play\n",
      "1      sunny   True   no\n",
      "12  overcast  False  yes\n",
      "\n",
      "Stopping at 2 instances\n",
      "\n",
      "===Information Gain===\n",
      "Windy = 0.994 - 0.683 = 0.311\n",
      "Temperature = 0.994 - 0.840 = 0.154\n",
      "Humidity = 0.994 - 0.683 = 0.311\n",
      "\n",
      "===Best Feature===\n",
      "Windy\n",
      "\n",
      "===Partitioned Dataset (True)===\n",
      "   Temperature Humidity Play\n",
      "1          hot     high   no\n",
      "6         cool   normal  yes\n",
      "5         cool   normal   no\n",
      "13        mild     high   no\n",
      "1          hot     high   no\n",
      "\n",
      "===Information Gain===\n",
      "Temperature = 0.722 - 0.400 = 0.322\n",
      "Humidity = 0.722 - 0.400 = 0.322\n",
      "\n",
      "===Best Feature===\n",
      "Temperature\n",
      "\n",
      "===Partitioned Dataset (hot)===\n",
      "  Humidity Play\n",
      "1     high   no\n",
      "1     high   no\n",
      "\n",
      "All instances have the same target feature value\n",
      "\n",
      "===Partitioned Dataset (cool)===\n",
      "  Humidity Play\n",
      "6   normal  yes\n",
      "5   normal   no\n",
      "\n",
      "All instances have the same descriptive features\n",
      "\n",
      "===Partitioned Dataset (mild)===\n",
      "   Humidity Play\n",
      "13     high   no\n",
      "\n",
      "All instances have the same target feature value\n",
      "\n",
      "===Partitioned Dataset (False)===\n",
      "   Temperature Humidity Play\n",
      "12         hot   normal  yes\n",
      "3         mild     high  yes\n",
      "9         mild   normal  yes\n",
      "0          hot     high   no\n",
      "4         cool   normal  yes\n",
      "\n",
      "===Information Gain===\n",
      "Temperature = 0.650 - 0.333 = 0.317\n",
      "Humidity = 0.650 - 0.333 = 0.317\n",
      "\n",
      "===Best Feature===\n",
      "Temperature\n",
      "\n",
      "===Partitioned Dataset (hot)===\n",
      "   Humidity Play\n",
      "12   normal  yes\n",
      "0      high   no\n",
      "\n",
      "Stopping at 2 instances\n",
      "\n",
      "===Partitioned Dataset (cool)===\n",
      "  Humidity Play\n",
      "4   normal  yes\n",
      "8   normal  yes\n",
      "\n",
      "All instances have the same target feature value\n",
      "\n",
      "===Partitioned Dataset (mild)===\n",
      "  Humidity Play\n",
      "3     high  yes\n",
      "9   normal  yes\n",
      "\n",
      "All instances have the same target feature value\n",
      "\n",
      "===Information Gain===\n",
      "Humidity = 0.994 - 0.000 = 0.994\n",
      "Temperature = 0.994 - 0.579 = 0.415\n",
      "Outlook = 0.994 - 0.751 = 0.243\n",
      "\n",
      "===Best Feature===\n",
      "Humidity\n",
      "\n",
      "===Partitioned Dataset (high)===\n",
      "   Temperature Outlook Play\n",
      "1          hot   sunny   no\n",
      "1          hot   sunny   no\n",
      "13        mild   rainy   no\n",
      "1          hot   sunny   no\n",
      "0          hot   sunny   no\n",
      "\n",
      "All instances have the same target feature value\n",
      "\n",
      "===Partitioned Dataset (normal)===\n",
      "   Temperature   Outlook Play\n",
      "6         cool  overcast  yes\n",
      "9         mild     rainy  yes\n",
      "8         cool     sunny  yes\n",
      "12         hot  overcast  yes\n",
      "8         cool     sunny  yes\n",
      "\n",
      "All instances have the same target feature value\n",
      "\n",
      "===Information Gain===\n",
      "Outlook = 0.994 - 0.549 = 0.445\n",
      "Humidity = 0.994 - 0.000 = 0.994\n",
      "Windy = 0.994 - 0.993 = 0.001\n",
      "\n",
      "===Best Feature===\n",
      "Humidity\n",
      "\n",
      "===Partitioned Dataset (high)===\n",
      "  Outlook  Windy Play\n",
      "1   sunny   True   no\n",
      "7   sunny  False   no\n",
      "7   sunny  False   no\n",
      "0   sunny  False   no\n",
      "7   sunny  False   no\n",
      "\n",
      "All instances have the same target feature value\n",
      "\n",
      "===Partitioned Dataset (normal)===\n",
      "     Outlook  Windy Play\n",
      "12  overcast  False  yes\n",
      "9      rainy  False  yes\n",
      "4      rainy  False  yes\n",
      "8      sunny  False  yes\n",
      "8      sunny  False  yes\n",
      "\n",
      "All instances have the same target feature value\n",
      "\n",
      "CPU times: user 228 ms, sys: 7.79 ms, total: 235 ms\n",
      "Wall time: 229 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.RandomForest at 0x134aa9690>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf = RandomForest(n_estimators=10, n_sample=len(X_train), criterion={'partition_threshold': 5})\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "457f95eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36mRandomForest.score\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscore\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m     27\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(X\u001b[38;5;241m.\u001b[39miloc[x]\u001b[38;5;241m.\u001b[39mto_frame()\u001b[38;5;241m.\u001b[39mT) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X))]\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:320\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros((n_labels, n_labels), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m--> 320\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintersect1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one label specified must be in y_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mintersect1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/numpy/lib/arraysetops.py:455\u001b[0m, in \u001b[0;36mintersect1d\u001b[0;34m(ar1, ar2, assume_unique, return_indices)\u001b[0m\n\u001b[1;32m    453\u001b[0m     aux \u001b[38;5;241m=\u001b[39m aux[aux_sort_indices]\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 455\u001b[0m     \u001b[43maux\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m mask \u001b[38;5;241m=\u001b[39m aux[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m==\u001b[39m aux[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    458\u001b[0m int1d \u001b[38;5;241m=\u001b[39m aux[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][mask]\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d903a974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
